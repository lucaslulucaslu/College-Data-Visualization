{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b328604-e10f-4c1c-9171-c315c014ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pymysql\n",
    "import os\n",
    "import time\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72238d6d-77a9-4f2b-a8a7-cc938a46b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_url_database(urls=[]):\n",
    "    connection=pymysql.connect(\n",
    "        db     = os.environ['db_name'],\n",
    "        user   = os.environ['db_user'],\n",
    "        passwd = os.environ['db_pass'],\n",
    "        host   = os.environ['db_host'],\n",
    "        port   = 3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    insert_count=0\n",
    "    for url in urls:\n",
    "        query=\"SELECT ID FROM fp_chatGPT.news_urls WHERE url LIKE %s\"\n",
    "        rows_count=cursor.execute(query,url)\n",
    "        if rows_count==0:\n",
    "            query=\"\"\"INSERT INTO `fp_chatGPT`.`news_urls` (`url`) VALUES (%s)\"\"\"\n",
    "            cursor.execute(query,url)\n",
    "            insert_count=insert_count+1\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return insert_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53524f6-0d16-46a7-8dd6-934016afd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "def Northeastern():\n",
    "    categories=[\n",
    "        \"https://news.northeastern.edu/category/university-news/\",\n",
    "        \"https://news.northeastern.edu/category/world-news/\",\n",
    "        \"https://news.northeastern.edu/category/science-technology/\",\n",
    "        \"https://news.northeastern.edu/category/arts-entertainment/\",\n",
    "        \"https://news.northeastern.edu/category/business/\",\n",
    "        \"https://news.northeastern.edu/category/health/\",\n",
    "        \"https://news.northeastern.edu/category/law/\",\n",
    "        \"https://news.northeastern.edu/category/lifestyle/\",\n",
    "        \"https://news.northeastern.edu/category/society-culture/\",\n",
    "        \"https://news.northeastern.edu/category/sports/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.results-list .results-list__grid .post-link > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Princeton():\n",
    "    categories=[\n",
    "        \"https://www.princeton.edu/news\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.news-run.item > div > div > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def MIT():\n",
    "    categories=[\n",
    "        \"https://news.mit.edu/school/engineering\",\n",
    "        \"https://news.mit.edu/school/humanities-arts-and-social-sciences\",\n",
    "        \"https://news.mit.edu/school/architecture-and-planning\",\n",
    "        \"https://news.mit.edu/school/management\",\n",
    "        \"https://news.mit.edu/school/science\",\n",
    "        \"https://news.mit.edu/school/mit-schwarzman-college-computing\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.term-page--news-article--item--title--link')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Harvard():\n",
    "    categories=[\n",
    "        \"https://news.harvard.edu/gazette/section/news_plus/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2.hentry__title.wp-block-post-title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Standford_med():\n",
    "    categories=[\n",
    "        \"https://med.stanford.edu/news.html\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.col-xs-9 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Yale():\n",
    "    categories=[\n",
    "        \"https://news.yale.edu/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.view > div.cards > article.card__item > a.card__body')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Chicago():\n",
    "    categories=[\n",
    "        \"https://news.uchicago.edu/lateststories\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.c-list__item-titlelink')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def JHU():\n",
    "    categories=[\n",
    "        \"https://hub.jhu.edu/university-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.count-10 > div.force > div.text > div.accent-element > h5 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UPenn():\n",
    "    categories=[\n",
    "        \"https://penntoday.upenn.edu/news/archives\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.search-tease__link')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Caltech():\n",
    "    categories=[\n",
    "        \"https://www.caltech.edu/about/news\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.block-NewsArticleListBlock .news-article-list .article-teaser__image-container a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Duke():\n",
    "    categories=[\n",
    "        \"https://today.duke.edu/trending\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.text-container > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Northwestern():\n",
    "    categories=[\n",
    "        \"https://news.northwestern.edu/stories/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "    \n",
    "def Dartmouth():\n",
    "    categories=[\n",
    "        \"https://home.dartmouth.edu/news?content-types=article#articles-list\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.views-row article a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Brown():\n",
    "    categories=[\n",
    "        \"https://www.brown.edu/news/all\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.news-items .news .component_body h3 a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Rice():\n",
    "    categories=[\n",
    "        \"https://news.rice.edu/news-releases\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.article__news-list-summary-label')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def WUSTL():\n",
    "    categories=[\n",
    "        \"https://source.wustl.edu/channels/newsroom/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.link-animate')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Cornell():\n",
    "    categories=[\n",
    "        \"https://news.cornell.edu/archive\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def NotreDame():\n",
    "    categories=[\n",
    "        \"https://news.nd.edu/latest-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.card-link')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UCB():\n",
    "    categories=[\n",
    "        \"https://news.berkeley.edu/all-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('article.preview--post .preview__body h2 a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UCLA():\n",
    "    categories=[\n",
    "        \"https://newsroom.ucla.edu/stories\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3.article-list-title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def CMU():\n",
    "    categories=[\n",
    "        \"https://www.cmu.edu/news/stories\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.link-box')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Emory():\n",
    "    categories=[\n",
    "        \"https://news.emory.edu/tags/topic/news_releases/index.html\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('li.tag-list-item > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Georgetown():\n",
    "    categories=[\n",
    "        \"https://www.georgetown.edu/news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.c--articles h3 a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UMich():\n",
    "    categories=[\n",
    "        \"https://news.umich.edu/all-stories/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('li.clearfix > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def USC():\n",
    "    categories=[\n",
    "        \"https://today.usc.edu/tag/usc-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('article h3>a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Virginia():\n",
    "    categories=[\n",
    "        \"https://news.virginia.edu/content/all-news\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.uva-today-news-item-title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UFL():\n",
    "    categories=[\n",
    "        \"https://news.ufl.edu/science/\",\n",
    "        \"https://news.ufl.edu/life/\",\n",
    "        \"https://news.ufl.edu/health/\",\n",
    "        \"https://news.ufl.edu/campus/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.article-listing .listing-card .h5 a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def WFU():\n",
    "    categories=[\n",
    "        \"https://news.wfu.edu/archive/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Tufts():\n",
    "    categories=[\n",
    "        \"https://now.tufts.edu/activism-social-justice\",\n",
    "        \"https://now.tufts.edu/arts-humanities\",\n",
    "        \"https://now.tufts.edu/business-economics\",\n",
    "        \"https://now.tufts.edu/climate-sustainability\",\n",
    "        \"https://now.tufts.edu/food-nutrition\",\n",
    "        \"https://now.tufts.edu/global-affairs\",\n",
    "        \"https://now.tufts.edu/health\",\n",
    "        \"https://now.tufts.edu/animal-health-medicine\",\n",
    "        \"https://now.tufts.edu/points-view\",\n",
    "        \"https://now.tufts.edu/politics-voting\",\n",
    "        \"https://now.tufts.edu/science-technology\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3.teaser__title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UCSB():\n",
    "    categories=[\n",
    "        \"https://news.ucsb.edu/all-news\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('span.field-content > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UCI():\n",
    "    categories=[\n",
    "        \"https://news.uci.edu/category/art-and-humanities/\",\n",
    "        \"https://news.uci.edu/category/athletics/\",\n",
    "        \"https://news.uci.edu/category/campus-life/\",\n",
    "        \"https://news.uci.edu/category/health/\",\n",
    "        \"https://news.uci.edu/category/science-and-tech/\",\n",
    "        \"https://news.uci.edu/category/society-and-community/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3.posts-grid-wide__post-title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UCSD():\n",
    "    categories=[\n",
    "        \"https://today.ucsd.edu/archives\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3.h4 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def BostonCollege():\n",
    "    categories=[\n",
    "        \"https://www.bc.edu/content/bc-web/sites/bc-news.html\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.bc-news-article-list-2022 .article-block>a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def BostonCollege():\n",
    "    categories=[\n",
    "        \"https://www.bc.edu/content/bc-web/sites/bc-news.html\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.bc-news-article-list-2022 .article-block>a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Rochester():\n",
    "    categories=[\n",
    "        \"https://www.rochester.edu/newscenter/category/news/sci-tech/\",\n",
    "        \"https://www.rochester.edu/newscenter/category/news/society-culture/\",\n",
    "        \"https://www.rochester.edu/newscenter/category/news/university-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.loop-item__title>a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UCDavis():\n",
    "    categories=[\n",
    "        \"https://www.ucdavis.edu/news/latest\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3.vm-teaser__title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UTexas():\n",
    "    categories=[\n",
    "        \"https://news.utexas.edu/archive/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2.ut-h3 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def WISC():\n",
    "    categories=[\n",
    "        \"https://news.wisc.edu/latest-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2.headline > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def BostonU():\n",
    "    categories=[\n",
    "        \"https://www.bu.edu/today/browse/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('a.wp-prepress-component-story-card-link')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UIUC():\n",
    "    categories=[\n",
    "        \"https://news.illinois.edu/view/6367?ACTION=POST_LIST\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h3.blog-post-title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def WilliamMary():\n",
    "    categories=[\n",
    "        \"https://news.wm.edu/latest-news/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('#main article h2 a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Brandeis():\n",
    "    categories=[\n",
    "        \"https://www.brandeis.edu/stories/2024/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('.wrap.wrap--xslim .feed .h6 a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Case():\n",
    "    categories=[\n",
    "        \"https://thedaily.case.edu/category/campus-community/\",\n",
    "        \"https://thedaily.case.edu/category/university-news/\",\n",
    "        \"https://thedaily.case.edu/category/research/\",\n",
    "        \"https://thedaily.case.edu/category/people/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2.title > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Rutgers():\n",
    "    categories=[\n",
    "        \"https://www.rutgers.edu/news/all\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('article.cc--news-card  h3 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Washington():\n",
    "    categories=[\n",
    "        \"https://www.washington.edu/news/the-latest-news-from-the-uw/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Purdue():\n",
    "    categories=[\n",
    "        \"https://www.purdue.edu/newsroom/archive.html\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.col-sm-8 > div > ul > li > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def UMaryland():\n",
    "    categories=[\n",
    "        \"https://today.umd.edu/articles-list\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('h2 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def TAMU():\n",
    "    categories=[\n",
    "        \"https://today.tamu.edu/archives/\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('span.headline-group__head > span > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def VT():\n",
    "    categories=[\n",
    "        \"https://news.vt.edu/articles.html\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('ul.vt-list-items li .vt-list-item-row .vt-list-title a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n\n",
    "\n",
    "def Lehigh():\n",
    "    categories=[\n",
    "        \"https://www2.lehigh.edu/news/all-stories\"\n",
    "    ]\n",
    "    n=0\n",
    "    for category in categories:\n",
    "        response=requests.get(category,headers = {'User-agent': user_agent})\n",
    "        html=response.content\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        links=soup.select('div.col-md-8 > a')\n",
    "        links_array=[urljoin(category,link.get('href')) for link in links]\n",
    "        n=n+insert_url_database(links_array)\n",
    "        time.sleep(3)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54fcaeb-09fe-45f0-bd23-ea2333c5dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colleges=[\n",
    "    Lehigh,    VT,    TAMU,    UMaryland,    Purdue,    Washington,    Rutgers,    Case,    Brandeis,    WilliamMary,    UIUC,    BostonU,    WISC,\n",
    "    UTexas,    UCDavis,    Rochester,    BostonCollege,    UCSD,    UCI,    UCSB,    Tufts,    UFL,    WFU,    Virginia,    USC,    UMich,    Georgetown,\n",
    "    Emory,    Northeastern,    Princeton,    MIT,    Harvard,    Standford_med,    Yale,    Chicago,    JHU,    UPenn,    Caltech,    Duke,    Northwestern,\n",
    "    Dartmouth,    Brown,    Rice,    WUSTL,    Cornell,    NotreDame,    UCB,    UCLA,    CMU,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dec335-62c2-49d6-9c1e-b02ea63a8061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lehigh 0\n",
      "VT 0\n",
      "TAMU 0\n",
      "UMaryland 0\n",
      "Purdue 3\n",
      "Washington 0\n",
      "Rutgers 2\n",
      "Case 2\n",
      "Brandeis 0\n",
      "WilliamMary 0\n",
      "UIUC 0\n",
      "BostonU 0\n",
      "WISC 0\n",
      "UTexas 0\n",
      "UCDavis 0\n",
      "Rochester 0\n",
      "BostonCollege 0\n",
      "UCSD 1\n",
      "UCI 0\n",
      "UCSB 0\n",
      "Tufts 0\n",
      "UFL 0\n",
      "WFU 0\n",
      "Virginia 0\n",
      "USC 1\n",
      "UMich 0\n",
      "Georgetown 0\n",
      "Emory 1\n",
      "Northeastern 0\n",
      "Princeton 0\n",
      "MIT 1\n",
      "Harvard 0\n",
      "Standford_med 2\n",
      "Yale 0\n",
      "Chicago 0\n",
      "JHU 0\n",
      "UPenn 0\n",
      "Caltech 0\n",
      "Duke 0\n",
      "Northwestern 0\n",
      "Dartmouth 4\n",
      "Brown 0\n",
      "Rice 0\n",
      "WUSTL 1\n",
      "Cornell 0\n",
      "NotreDame 1\n",
      "UCB 0\n",
      "UCLA 0\n",
      "CMU 0\n"
     ]
    }
   ],
   "source": [
    "for college in colleges:\n",
    "    print(college.__name__,college())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda8c7c-060c-4f99-b7a6-2dec795c1f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
