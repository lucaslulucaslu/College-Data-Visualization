{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cab3aa-d600-4e0c-8b94-5b4064d75a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from typing import List, Literal\n",
    "import tiktoken\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from LLM_get_folder import get_local_folder\n",
    "from PIL import Image\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "model_small=\"gpt-3.5-turbo\"\n",
    "\n",
    "model_large=\"gpt-4o\"\n",
    "\n",
    "llm_small=ChatOpenAI(model=model_small, temperature=0, timeout=40000)\n",
    "llm_large = ChatOpenAI(model=model_large, temperature=0, timeout=40000)\n",
    "# llm = ChatOpenAI()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"college-information-llm\"\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "MAX_WEB_URL = 5\n",
    "MAX_QUERY_RESULT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0ba4f-847e-4068-8345-641dc18fe35d",
   "metadata": {},
   "source": [
    "------------------------------get college information----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6fc6cf-b3e9-4619-a151-9e0d49d62f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(\n",
    "    db=os.environ[\"db_name\"],\n",
    "    user=os.environ[\"db_user\"],\n",
    "    passwd=os.environ[\"db_pass\"],\n",
    "    host=os.environ[\"db_host\"],\n",
    "    port=3306,\n",
    "    cursorclass=pymysql.cursors.DictCursor,\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "query = \"\"\"SELECT t3.year,t2.postid,t2.cname,t2.name,t3.rank,t1.`term_id` as tag_id FROM fp_forwardpathway.`wp_mmcp_terms` t1 \n",
    "JOIN fp_ranking.colleges t2 ON t2.cname=REPLACE(t1.name,'相关新闻','')\n",
    "JOIN fp_ranking.us_rankings t3 ON t3.postid=t2.postid AND t3.year=(select ranking FROM fp_IPEDS.latest_information) AND t3.type=1\n",
    "WHERE t1.`name` LIKE '%相关新闻%'\"\"\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "colleges = pd.DataFrame(columns=[\"year\", \"postid\", \"cname\", \"name\", \"rank\", \"tag_id\"])\n",
    "for row in rows:\n",
    "    colleges = pd.concat([colleges, pd.DataFrame([row])])\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "temp = colleges[\n",
    "    colleges[\"name\"].str.startswith(\"University of Illinois at Urbana-Champaign\")\n",
    "]\n",
    "colleges = pd.concat([colleges, temp])\n",
    "colleges.iloc[colleges.shape[0] - 1, 2] = \"伊利诺伊大学厄巴纳-香槟分校\"\n",
    "temp = colleges[colleges[\"name\"].str.startswith(\"Purdue University\")]\n",
    "colleges = pd.concat([colleges, temp])\n",
    "colleges.iloc[colleges.shape[0] - 1, 2] = \"普渡大学\"\n",
    "temp = colleges[colleges[\"name\"].str.startswith(\"University of Maryland\")]\n",
    "colleges = pd.concat([colleges, temp])\n",
    "colleges.iloc[colleges.shape[0] - 1, 2] = \"马里兰大学\"\n",
    "\n",
    "colleges = colleges.reset_index(drop=True)\n",
    "ranking_year = colleges[\"year\"][0]\n",
    "colleges.drop(columns=[\"year\"], inplace=True)\n",
    "colleges = colleges.reindex(\n",
    "    colleges[\"cname\"].str.len().sort_values(ascending=False).index\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b31f868-5914-450c-8dc2-a4a003ad286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    url: str\n",
    "    summary: str\n",
    "    topics: List[str]\n",
    "    documents: str\n",
    "    image_query: str\n",
    "    title: str\n",
    "    content: str\n",
    "    tags: set\n",
    "    image_url: str\n",
    "    image_ID: int\n",
    "    image_filename: str\n",
    "    reference: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e0c942-2c1f-4f2c-a63b-71682195898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_output(BaseModel):\n",
    "    title: str = Field(description=\"网页内容总结标题，标题的语言必须是英文\")\n",
    "    summary: str = Field(description=\"网页内容总结内容，总结内容的语言必须是中文\")\n",
    "\n",
    "\n",
    "def summary_from_url(url):\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import SeleniumURLLoader\n",
    "    loader =SeleniumURLLoader(urls=[])\n",
    "    docs=loader.load()\n",
    "    \"\"\"\n",
    "    summary_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"你是一名专业的新闻总结员，下面给出的网页内容是一篇新闻，请从该新闻内容总结一段800个汉字左右的总结，总结内容必须使用中文输出。总结要全面，字数大约在800个汉字左右。\n",
    "                如果网页内容中包含新闻发布日期的，请在总结中也包含该日期，日期要包含年份。如果网页内容中提到美国大学的，请在总结中也包含该大学的相关内容。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"网页内容: {content}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        loader = WebBaseLoader(url)\n",
    "        #loader.requests_kwargs = {\"verify\": False}\n",
    "        docs = loader.load()\n",
    "        content=docs[0].page_content\n",
    "        encoding = tiktoken.encoding_for_model(model_small)\n",
    "        token_length=len(encoding.encode(content))\n",
    "        if token_length<=15000:\n",
    "            structured_llm = llm_small.with_structured_output(summary_output)\n",
    "        else:\n",
    "            structured_llm = llm_large.with_structured_output(summary_output)\n",
    "        summary_chain = summary_prompt | structured_llm\n",
    "        response = summary_chain.invoke({\"content\": content})\n",
    "    except:\n",
    "        response=None\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c397edf-8768-42f7-a657-f94834ad31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(state):\n",
    "    url = state[\"url\"]\n",
    "    response = summary_from_url(url)\n",
    "    title = response.title\n",
    "    summary = response.summary\n",
    "    print(\"Finish Initial Summary: \", url)\n",
    "    url_base=url.split('?')[0]\n",
    "    return {\"summary\": summary, \"reference\": {url_base: title}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5785bf-d1e7-4db8-9796-46db2331b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class more_points(BaseModel):\n",
    "    more: list[str] = Field(\n",
    "        description=\"可以展开讨论的点的搜索查询，必须是英文搜索查询\"\n",
    "    )\n",
    "\n",
    "\n",
    "def more_topics(state):\n",
    "    summary = state[\"summary\"]\n",
    "    structured_llm = llm_large.with_structured_output(more_points)\n",
    "    more_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"从下面用户给出的一段原始总结文字中提出不少于'两'点但不多于'四'点与原文有联系且可以展开讨论的点, 请给出详细的搜索查询来代表这几个点，搜索查询必须要完整且详细，\n",
    "                搜索查询必须为英文，不管输入内容是什么语言，输出的搜索查询必须是英文查询。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"原始总结文字：{summary}\"),\n",
    "        ]\n",
    "    )\n",
    "    more_chain = more_prompt | structured_llm\n",
    "    topics = more_chain.invoke({\"summary\": summary})\n",
    "    return {\"topics\": topics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933f7ba9-6ccb-471d-a6e7-b986154a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    search = GoogleSerperAPIWrapper(type=\"news\")\n",
    "    queries = state[\"topics\"].more\n",
    "    reference = state[\"reference\"]\n",
    "    documents = \"\"\n",
    "    n_urls = 0\n",
    "    for query in queries:\n",
    "        if n_urls >= MAX_WEB_URL:\n",
    "            break\n",
    "        results = search.results(query)\n",
    "        n_results = 0\n",
    "        for result in results[\"news\"]:\n",
    "            url = result[\"link\"]\n",
    "            url_base=url.split('?')[0]\n",
    "            if url_base in reference:\n",
    "                continue\n",
    "            else:\n",
    "                response = summary_from_url(url)\n",
    "                if response is not None:\n",
    "                    print(\"------ Topics Summary: \", url)\n",
    "                    doc = response.summary\n",
    "                    title = response.title\n",
    "                    reference[url_base] = title\n",
    "                    documents = documents + query + \"\\n\\n\" + doc + \"\\n\\n\"\n",
    "                    n_urls = n_urls + 1\n",
    "                    n_results = n_results + 1\n",
    "                    if n_results >= MAX_QUERY_RESULT:\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "    return {\"documents\": documents, \"reference\": reference}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cbcf86-74c8-4a8c-ad91-1f172cc2f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    summary = state[\"summary\"]\n",
    "    documents = state[\"documents\"]\n",
    "    topics = state[\"topics\"].more\n",
    "    content_array = []\n",
    "    content_set = {}\n",
    "    repeat_N = 0\n",
    "    system_message = \"\"\"你的角色是一名专业的美国大学新闻评论员，下面给出一段原始总结内容，同时给你一些可以扩展讨论的点以及支持这些讨论点的讨论，请重新写一遍2000-4000中文字数的评论文章，字数可以根据内容的多少来适当选择，但不能少于2000字也不能多余4000字。\n",
    "                    评论文章内容应围绕原始总结的内容，对与美国大学相关的内容要额外关注，适当的结合讨论点扩展讨论，在扩展讨论的时候需要前后呼应提及与原始总结相关联的联系，最后需要综合原始总结和扩展讨论再做一个最后的总结，文章前后逻辑关系需要连贯，如果有需要可以重写全文，\n",
    "                    文章中如果遇到美国大学名称，第一次必须使用美国大学的中文全名，之后可以适当使用缩写，美国大学的全名要使用最普遍的中文翻译版本，遇到加利福尼亚大学各个分校一律使用加州大学+分校名称。\n",
    "                    遇到布兰戴斯大学请使用布兰迪斯大学，遇到威廉与玛丽学院请使用威廉玛丽学院，遇到加州大学欧文分校请使用加州大学尔湾分校，遇到利哈伊大学请使用里海大学，遇到密歇根大学安娜堡分校要使用全称，不能缩写成密歇根大学，\n",
    "                    遇到伊利诺伊大学香槟分校要使用全程，不能缩写成伊利诺伊大学；遇到乔治亚大学请使用佐治亚大学\n",
    "                    在文章中合适的位置，比如中上部位且在两个段落之间，需要放置一个且必须有一个图片空位，用'[image_placeholder]'代表这个图片空位。\"\"\"\n",
    "    while len(content_array) == 0 or (len(content_array) - len(content_set)) > 0:\n",
    "        rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_message),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"原始总结：\\n\\n{summary},\\n\\n扩展讨论点：\\n\\n{topics},\\n\\n支持扩展讨论点的讨论：\\n\\n{documents}\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        rewrite_chain = rewrite_prompt | llm_large | StrOutputParser()\n",
    "        content = rewrite_chain.invoke(\n",
    "            {\"summary\": summary, \"topics\": topics, \"documents\": documents}\n",
    "        )\n",
    "        content_array = content.split(\"\\n\\n\")\n",
    "        for element in content_array:\n",
    "            if len(element) <= 20:\n",
    "                content_array.remove(element)\n",
    "        content_set = set(content_array)\n",
    "        repeat_N = repeat_N + 1\n",
    "        if repeat_N >= 4:\n",
    "            local_folder = get_local_folder()\n",
    "            file = os.path.join(get_local_folder(), \"repeat.txt\")\n",
    "            f = open(file, \"a\")\n",
    "            f.write(\n",
    "                content\n",
    "                + \"\\n\\n---------------------------------------------------------------------\\n\\n\"\n",
    "            )\n",
    "            f.close()\n",
    "            break\n",
    "        system_message = (\n",
    "            system_message\n",
    "            + \"\\n\\n新的文章不要有重复的段落，如果遇到原始总结内容和扩展讨论点有重复内容的可以忽略重复内容，在最后的输出文章中不可以有重复段落。\"\n",
    "        )\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89016558-85c0-450f-8d23-7613f7097793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class meta_format(BaseModel):\n",
    "    title: str = Field(description=\"与文章内容相关的文章标题，用中文输出\")\n",
    "    image_query: str = Field(\n",
    "        description=\"detailed prompt to generate an image that based on the article content, should be in English\"\n",
    "    )\n",
    "    image_filename: str = Field(\n",
    "        description=\"a good name for the image file without file extension, should be in English\"\n",
    "    )\n",
    "    tags: List[str] = Field(description=\"与文章内容相关的标签，用中文输出\")\n",
    "\n",
    "\n",
    "def article_metas(state):\n",
    "    content = state[\"content\"]\n",
    "    meta_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"下面给出一文章的内容，请给文章取一个合适的标题，文章标题需要使用中文。\n",
    "                同时生成一些与文章内容相关的标签，标签需要使用中文。\n",
    "                also generate a detailed prompt to generate an image that based on the article content, the image generation prompt should be in English, be careful with prompt words, use safe words that won't violate 'safety system'. \n",
    "                also generate a image file name without file type extension regarding this image prompt, the image filename should also be in English.\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"content：\\n\\n{content}\"),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm_large.with_structured_output(meta_format)\n",
    "    meta_chain = meta_prompt | structured_llm\n",
    "    response = meta_chain.invoke({\"content\": content})\n",
    "    tag_names = response.tags\n",
    "    tags = tags_to_IDs(tag_names)\n",
    "    return {\n",
    "        \"title\": response.title,\n",
    "        \"image_query\": response.image_query,\n",
    "        \"image_filename\": response.image_filename,\n",
    "        \"tags\": tags,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608b2528-512c-4ac4-82af-ad1cf0dbff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_article(state):\n",
    "    content = state[\"content\"]\n",
    "    tags = state[\"tags\"]\n",
    "    reference = state[\"reference\"]\n",
    "    n = 0\n",
    "    for index, row in colleges.iterrows():\n",
    "        tag_id = row[\"tag_id\"]\n",
    "        cname = row[\"cname\"]\n",
    "        postid = row[\"postid\"]\n",
    "        if content.find(cname) >= 0:\n",
    "            content = content.replace(\n",
    "                cname, \"[insert_link postid={} /insert_link]\".format(postid)\n",
    "            )\n",
    "            tags.add(tag_id)\n",
    "    links = re.findall(r\"\\[insert_link postid=\\d+ \\/insert_link\\]\", content)\n",
    "    for link in links:\n",
    "        postid = int(re.search(r\"\\d+\", link).group())\n",
    "        row = colleges[colleges[\"postid\"] == postid].iloc[0]\n",
    "        cname = row[\"cname\"]\n",
    "        rank = row[\"rank\"]\n",
    "        if n == 0:\n",
    "            content = content.replace(\n",
    "                link,\n",
    "                \"[{}](https://www.forwardpathway.com/{})（{}USNews[美国大学排名](https://www.forwardpathway.com/ranking)：{}）\".format(\n",
    "                    cname, postid, ranking_year, rank\n",
    "                ),\n",
    "                1,\n",
    "            )\n",
    "            n = n + 1\n",
    "        else:\n",
    "            content = content.replace(\n",
    "                link, \"[{}](https://www.forwardpathway.com/{})\".format(cname, postid), 1\n",
    "            )\n",
    "        content = content.replace(link, cname)\n",
    "    content = content + \"\"\"\\n### 参考新闻资料:\"\"\"\n",
    "    for key in reference:\n",
    "        content = content + \"\"\"\\n1. [{}]({})\"\"\".format(reference[key], key)\n",
    "    return {\"content\": content, \"tags\": tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3babcedf-31fa-4bfa-9003-69627a21c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_url = \"https://www.forwardpathway.com/wp-json/wp/v2\"\n",
    "wp_post_url = wp_url + \"/posts\"\n",
    "wp_media_url = wp_url + \"/media\"\n",
    "wp_tag_url = wp_url + \"/tags\"\n",
    "\n",
    "user_id = os.environ[\"wordpress_username\"]\n",
    "# user app password can be created in the user/edit user/application password\n",
    "user_app_password = os.environ[\"wordpress_pass\"]\n",
    "\n",
    "credentials = user_id + \":\" + user_app_password\n",
    "token = base64.b64encode(credentials.encode())\n",
    "header = {\"Authorization\": \"Basic \" + token.decode(\"utf-8\")}\n",
    "\n",
    "\n",
    "def tags_to_IDs(tag_names=[]):\n",
    "    tags = set()\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    for tag_name in tag_names:\n",
    "        query = \"\"\"SELECT t1.term_id FROM fp_forwardpathway.wp_mmcp_terms t1 JOIN fp_forwardpathway.wp_mmcp_term_taxonomy t2 ON t2.term_id=t1.term_id AND t2.taxonomy=\"post_tag\" WHERE t1.name=%s\"\"\"\n",
    "        rows_count = cursor.execute(query, tag_name)\n",
    "        if rows_count > 0:\n",
    "            result = cursor.fetchone()\n",
    "            tags.add(result[\"term_id\"])\n",
    "        else:\n",
    "            tag_data = {\"name\": tag_name}\n",
    "            response = requests.post(wp_tag_url, headers=header, json=tag_data)\n",
    "            tags.add(response.json()[\"id\"])\n",
    "\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return tags\n",
    "\n",
    "\n",
    "def post_post(\n",
    "    article_title, article_body, post_status=\"publish\", featured_media_id=0, tags={}\n",
    "):\n",
    "    post_data = {\n",
    "        \"title\": article_title,\n",
    "        \"content\": article_body,\n",
    "        \"comment_status\": \"closed\",\n",
    "        \"categories\": [3627],  # 美国大学相关新闻category\n",
    "        \"tags\": list(tags),\n",
    "        \"status\": post_status,\n",
    "        \"featured_media\": featured_media_id,\n",
    "    }\n",
    "    response = requests.post(wp_post_url, headers=header, json=post_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def post_file(file_path):\n",
    "    media = {\n",
    "        \"file\": open(file_path, \"rb\"),\n",
    "        \"caption\": \"LLM_auto_post_test_file_\" + file_path,\n",
    "    }\n",
    "    response = requests.post(wp_media_url, headers=header, files=media)\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_image(state):\n",
    "    image_filename = state[\"image_filename\"]\n",
    "    image_folder = os.path.join(get_local_folder(), \"images\")\n",
    "    png_image = os.path.join(image_folder, image_filename + \".png\")\n",
    "    jpg_image = os.path.join(image_folder, image_filename + \".jpg\")\n",
    "    image_query = state[\"image_query\"]\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(\n",
    "            model=\"dall-e-3\", size=\"1792x1024\", quality=\"standard\"\n",
    "        ).run(image_query)\n",
    "        urllib.request.urlretrieve(image_url, png_image)\n",
    "        image = Image.open(png_image)\n",
    "        image.save(jpg_image, optimized=True, quality=20)\n",
    "        response = post_file(jpg_image)\n",
    "        response = response.json()\n",
    "        return {\n",
    "            \"image_ID\": int(response.get(\"id\")),\n",
    "            \"image_url\": response.get(\"guid\").get(\"rendered\"),\n",
    "        }\n",
    "    except:\n",
    "        return {\"image_ID\": -1, \"image_url\": \"\"}\n",
    "\n",
    "\n",
    "def publish_post(state):\n",
    "    title = state[\"title\"]\n",
    "    image_ID = state[\"image_ID\"]\n",
    "    image_url = state[\"image_url\"]\n",
    "    tags = state[\"tags\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.com/wp-content/uploads/2024/06/fp_college_news_default.jpg\"\n",
    "        image_ID = 107009\n",
    "    content = markdown.markdown(\n",
    "        state[\"content\"].replace(\n",
    "            \"[image_placeholder]\", \"\"\"<img src=\"{}\">\"\"\".format(image_url)\n",
    "        )\n",
    "    )\n",
    "    post_post(\n",
    "        title, content, post_status=\"publish\", featured_media_id=image_ID, tags=tags\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d97d8c7-e31a-4d3f-9914-1b44d7b250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"summary_node\", summary)\n",
    "workflow.add_node(\"more_topics\", more_topics)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"article_metas\", article_metas)\n",
    "workflow.add_node(\"format_article\", format_article)\n",
    "workflow.add_node(\"generate_image\", generate_image)\n",
    "workflow.add_node(\"publish_post\", publish_post)\n",
    "\n",
    "workflow.set_entry_point(\"summary_node\")\n",
    "workflow.add_edge(\"summary_node\", \"more_topics\")\n",
    "workflow.add_edge(\"more_topics\", \"web_search\")\n",
    "workflow.add_edge(\"web_search\", \"rewrite\")\n",
    "workflow.add_edge(\"rewrite\", \"article_metas\")\n",
    "workflow.add_edge(\"article_metas\", \"format_article\")\n",
    "workflow.add_edge(\"format_article\", \"generate_image\")\n",
    "workflow.add_edge(\"generate_image\", \"publish_post\")\n",
    "workflow.add_edge(\"publish_post\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d527dae-576f-4c75-98e8-17f917e0dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls():\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    query = \"SELECT url FROM fp_chatGPT.news_urls WHERE post IS NULL OR post = 0 ORDER BY RAND() LIMIT 1\"\n",
    "    rows_count = cursor.execute(query)\n",
    "    if rows_count > 0:\n",
    "        rows = cursor.fetchall()\n",
    "        urls = [row[\"url\"] for row in rows]\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb88859-ae79-4046-abd8-5e0a37266760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_url_flag(url=\"\"):\n",
    "    if len(url) > 0:\n",
    "        connection = pymysql.connect(\n",
    "            db=os.environ[\"db_name\"],\n",
    "            user=os.environ[\"db_user\"],\n",
    "            passwd=os.environ[\"db_pass\"],\n",
    "            host=os.environ[\"db_host\"],\n",
    "            port=3306,\n",
    "            cursorclass=pymysql.cursors.DictCursor,\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "        query = \"UPDATE fp_chatGPT.news_urls SET post=1 WHERE url=%s\"\n",
    "        cursor.execute(query, url)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64236d7d-b439-46b0-b352-71e34f2e6b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Initial Summary:  https://news.umich.edu/maternal-suicide-u-m-study-provides-insights-into-complicating-factors-surrounding-perinatal-deaths/\n",
      "------ Topics Summary:  https://medicalxpress.com/news/2024-06-maternal-suicide-insights-complicating-factors.html\n",
      "------ Topics Summary:  https://www.nature.com/articles/s41591-023-02629-5\n",
      "------ Topics Summary:  https://www.news-medical.net/news/20240623/How-does-prenatal-cannabis-use-affect-neonatal-outcomes.aspx\n",
      "------ Topics Summary:  https://www.who.int/news-room/fact-sheets/detail/newborn-mortality\n",
      "1 finished\n"
     ]
    }
   ],
   "source": [
    "urls = get_urls()\n",
    "n_url = 0\n",
    "for url in urls:\n",
    "    try:\n",
    "        app.invoke({\"url\": url})\n",
    "        set_url_flag(url)\n",
    "        n_url = n_url + 1\n",
    "        print(n_url, \"finished\")\n",
    "    except Exception as e:\n",
    "        print(\"error for url: \", url)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a351e50-6a12-4446-99fb-16b55a489c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
