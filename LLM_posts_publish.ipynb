{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cab3aa-d600-4e0c-8b94-5b4064d75a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import markdown\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import pymysql\n",
    "import re\n",
    "from LLM_get_folder import get_local_folder\n",
    "\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o',temperature=0,timeout=40000)\n",
    "#llm = ChatOpenAI()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'college-information-llm'\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "MAX_WEB_URL=5\n",
    "MAX_QUERY_RESULT=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0ba4f-847e-4068-8345-641dc18fe35d",
   "metadata": {},
   "source": [
    "------------------------------get college information----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6fc6cf-b3e9-4619-a151-9e0d49d62f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection=pymysql.connect(\n",
    "    db     = os.environ['db_name'],\n",
    "    user   = os.environ['db_user'],\n",
    "    passwd = os.environ['db_pass'],\n",
    "    host   = os.environ['db_host'],\n",
    "    port   = 3306,\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "query=\"\"\"SELECT t3.year,t2.postid,t2.cname,t2.name,t3.rank,t1.`term_id` as tag_id FROM fp_forwardpathway.`wp_mmcp_terms` t1 \n",
    "JOIN fp_ranking.colleges t2 ON t2.cname=REPLACE(t1.name,'相关新闻','')\n",
    "JOIN fp_ranking.us_rankings t3 ON t3.postid=t2.postid AND t3.year=(select ranking FROM fp_IPEDS.latest_information) AND t3.type=1\n",
    "WHERE t1.`name` LIKE '%相关新闻%'\"\"\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "colleges=pd.DataFrame(columns=['year','postid','cname','name','rank','tag_id'])\n",
    "for row in rows:\n",
    "    colleges=pd.concat([colleges,pd.DataFrame([row])])\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "temp=colleges[colleges['name'].str.startswith('University of Illinois at Urbana-Champaign')]\n",
    "colleges=pd.concat([colleges,temp])\n",
    "colleges.iloc[colleges.shape[0]-1,2]=\"伊利诺伊大学厄巴纳-香槟分校\"\n",
    "temp=colleges[colleges['name'].str.startswith('Purdue University')]\n",
    "colleges=pd.concat([colleges,temp])\n",
    "colleges.iloc[colleges.shape[0]-1,2]=\"普渡大学\"\n",
    "temp=colleges[colleges['name'].str.startswith('University of Maryland')]\n",
    "colleges=pd.concat([colleges,temp])\n",
    "colleges.iloc[colleges.shape[0]-1,2]=\"马里兰大学\"\n",
    "\n",
    "colleges=colleges.reset_index(drop=True)\n",
    "ranking_year=colleges['year'][0]\n",
    "colleges.drop(columns=['year'],inplace=True)\n",
    "colleges=colleges.reindex(colleges['cname'].str.len().sort_values(ascending=False).index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b31f868-5914-450c-8dc2-a4a003ad286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    url: str\n",
    "    summary: str\n",
    "    topics: List[str]\n",
    "    documents:str\n",
    "    image_query:str\n",
    "    title:str\n",
    "    content:str\n",
    "    tags:set\n",
    "    image_url:str\n",
    "    image_ID:int\n",
    "    image_filename:str\n",
    "    reference:dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e0c942-2c1f-4f2c-a63b-71682195898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_output(BaseModel):\n",
    "    title:str=Field(description=\"网页内容总结标题，标题的语言必须是英文\")\n",
    "    summary:str=Field(description=\"网页内容总结内容，总结内容的语言必须是中文\")\n",
    "def summary_from_url(url):\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import SeleniumURLLoader\n",
    "    loader =SeleniumURLLoader(urls=[])\n",
    "    docs=loader.load()\n",
    "    \"\"\"\n",
    "    loader = WebBaseLoader(url)\n",
    "    loader.requests_kwargs = {'verify':False}\n",
    "    docs=loader.load()\n",
    "    summary_prompt = ChatPromptTemplate.from_messages([\n",
    "                ('system',\"\"\"下面是网页内容，从该网页内容总结一段500个中文字数左右的总结，总结内容必须使用中文输出。\n",
    "                遇到密歇根大学安娜堡分校要使用全称，不能缩写成密歇根大学，遇到伊利诺伊大学香槟分校要使用全程，不能缩写成伊利诺伊大学\"\"\"),\n",
    "                ('human',\"网页内容: {content}\")\n",
    "            ])\n",
    "    structured_llm=llm.with_structured_output(summary_output)\n",
    "    summary_chain = summary_prompt | structured_llm\n",
    "    response=summary_chain.invoke({'content':docs})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c397edf-8768-42f7-a657-f94834ad31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(state):\n",
    "    url=state['url']\n",
    "    response=summary_from_url(url)\n",
    "    title=response.title\n",
    "    summary=response.summary\n",
    "    print(\"Finish Initial Summary: \",url)\n",
    "    return {\"summary\":summary,\"reference\":{url:title}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5785bf-d1e7-4db8-9796-46db2331b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class more_points(BaseModel):\n",
    "    more:list[str]=Field(description=\"可以展开讨论的点的搜索查询，必须是英文搜索查询\")\n",
    "def more_topics(state):\n",
    "    summary=state['summary']\n",
    "    structured_llm=llm.with_structured_output(more_points)\n",
    "    more_prompt=ChatPromptTemplate.from_messages([\n",
    "                ('system',\"\"\"从下面用户给出的一段原始总结文字中提出不少于'两'点但不多于'四'点与原文有联系且可以展开讨论的点, 请给出详细的搜索查询来代表这几个点，搜索查询必须要完整且详细，搜索查询必须为英文，不管输入内容是什么语言，输出的搜索查询必须是英文查询。\"\"\"),\n",
    "                ('human',\"原始总结文字：{summary}\")\n",
    "            ])\n",
    "    more_chain=more_prompt|structured_llm\n",
    "    topics=more_chain.invoke({'summary':summary})\n",
    "    return {\"topics\":topics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933f7ba9-6ccb-471d-a6e7-b986154a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    search = GoogleSerperAPIWrapper(type=\"news\")\n",
    "    queries=state['topics'].more\n",
    "    reference=state['reference']\n",
    "    documents=''\n",
    "    n_urls=0\n",
    "    for query in queries:\n",
    "        if n_urls>=MAX_WEB_URL:\n",
    "            break\n",
    "        results=search.results(query)\n",
    "        n_results=0\n",
    "        for result in results['news']:\n",
    "            url=result['link']\n",
    "            if url in reference:\n",
    "                continue\n",
    "            else:\n",
    "                response=summary_from_url(url)\n",
    "                print(\"------ Topics Summary: \",url)\n",
    "                doc=response.summary\n",
    "                title=response.title\n",
    "                reference[url]=title\n",
    "                documents=documents+query+\"\\n\\n\"+doc+\"\\n\\n\"\n",
    "                n_urls=n_urls+1\n",
    "                n_results=n_results+1\n",
    "                if n_results>=MAX_QUERY_RESULT:\n",
    "                    break\n",
    "    return({\"documents\":documents,\"reference\":reference})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cbcf86-74c8-4a8c-ad91-1f172cc2f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    summary=state['summary']\n",
    "    documents=state['documents']\n",
    "    topics=state['topics']\n",
    "    rewrite_prompt=ChatPromptTemplate.from_messages([\n",
    "                ('system',\"\"\"你的角色是一名专业的新闻评论员，下面给出一段原始总结内容，同时给你一些可以扩展讨论的点以及支持这些讨论点的文章，请重新写一遍大概2000-4000中文字数的文章，字数可以根据内容的多少来适当选择，但不能少于2000字也不能多余4000字。\n",
    "                新文章内容应围绕原始总结的内容，适当的结合讨论点扩展讨论，在扩展讨论的时候需要前后呼应提及与原始总结相关联的联系，最后需要综合原始总结和扩展讨论再做一个最后的总结，文章前后逻辑关系需要连贯，如果有需要可以重写全文，\n",
    "                文章中如果遇到美国大学名称，第一次必须使用美国大学的中文全名，之后可以适当使用缩写，美国大学的全名要使用最普遍的中文翻译版本，遇到加利福尼亚大学各个分校一律使用加州大学+分校名称。\n",
    "                遇到布兰戴斯大学请使用布兰迪斯大学，遇到威廉与玛丽学院请使用威廉玛丽学院，遇到加州大学欧文分校请使用加州大学尔湾分校\n",
    "                在文章中合适的位置，比如中上部位且在两个段落之间，需要放置一个且必须有一个图片空位，用'[image_placeholder]'代表这个图片空位。\"\"\"),\n",
    "                ('human',\"原始总结：\\n\\n{summary},\\n\\n扩展讨论点：\\n\\n{topics},\\n\\n支持讨论点的文章：\\n\\n{documents}\")\n",
    "            ])\n",
    "    rewrite_chain=rewrite_prompt|llm|StrOutputParser()\n",
    "    content=rewrite_chain.invoke({\"summary\":summary,\"topics\":topics,\"documents\":documents})\n",
    "    return ({\"content\":content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89016558-85c0-450f-8d23-7613f7097793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class meta_format(BaseModel):\n",
    "    title:str=Field(description=\"与文章内容相关的文章标题，用中文输出\")\n",
    "    image_query:str=Field(description=\"detailed prompt to generate an image that based on the article content, should be in English\")\n",
    "    image_filename:str=Field(description=\"a good name for the image file without file extension, should be in English\")\n",
    "    tags:List[str]=Field(description=\"与文章内容相关的标签，用中文输出\")\n",
    "def article_metas(state):\n",
    "    content=state['content']\n",
    "    meta_prompt=ChatPromptTemplate.from_messages([\n",
    "                ('system',\"\"\"下面给出一文章的内容，请给文章取一个合适的标题，文章标题需要使用中文。\n",
    "                同时生成一些与文章内容相关的标签，标签需要使用中文。\n",
    "                also generate a detailed prompt to generate an image that based on the article content, the image generation prompt should be in English, \n",
    "                also generate a image file name without file type extension regarding this image prompt, the image filename should also be in English.\"\"\"),\n",
    "                ('human',\"content：\\n\\n{content}\")\n",
    "            ])\n",
    "    structured_llm=llm.with_structured_output(meta_format)\n",
    "    meta_chain=meta_prompt|structured_llm\n",
    "    response=meta_chain.invoke({\"content\":content})\n",
    "    tag_names=response.tags\n",
    "    tags=tags_to_IDs(tag_names)\n",
    "    return ({\"title\":response.title,\"image_query\":response.image_query,\"image_filename\":response.image_filename,\"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608b2528-512c-4ac4-82af-ad1cf0dbff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_article(state):\n",
    "    content=state['content']\n",
    "    tags=state['tags']\n",
    "    reference=state['reference']\n",
    "    n=0\n",
    "    for index,row in colleges.iterrows():\n",
    "        tag_id=row['tag_id']\n",
    "        cname=row['cname']\n",
    "        postid=row['postid']\n",
    "        if content.find(cname)>=0:\n",
    "            content=content.replace(cname,\"[insert_link postid={} /insert_link]\".format(postid))\n",
    "            tags.add(tag_id)\n",
    "    links=re.findall(r'\\[insert_link postid=\\d+ \\/insert_link\\]',content)\n",
    "    for link in links:\n",
    "        postid=int(re.search(r'\\d+',link).group())\n",
    "        row=colleges[colleges['postid']==postid].iloc[0]\n",
    "        cname=row['cname']\n",
    "        rank=row['rank']\n",
    "        if n==0:\n",
    "            content=content.replace(link,\"[{}](https://www.forwardpathway.com/{})（{}USNews[美国大学排名](https://www.forwardpathway.com/ranking)：{}）\".format(cname,postid,ranking_year,rank),1)\n",
    "            n=n+1\n",
    "        else:\n",
    "            content=content.replace(link,\"[{}](https://www.forwardpathway.com/{})\".format(cname,postid),1)\n",
    "        content=content.replace(link,cname)\n",
    "    content=content+\"\"\"\\n### 参考新闻资料:\"\"\"\n",
    "    for key in reference:\n",
    "        content=content+\"\"\"\\n1. [{}]({})\"\"\".format(reference[key],key)\n",
    "    return({\"content\":content,\"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3babcedf-31fa-4bfa-9003-69627a21c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_url = \"https://www.forwardpathway.com/wp-json/wp/v2\"\n",
    "wp_post_url = wp_url + \"/posts\"\n",
    "wp_media_url = wp_url + \"/media\"\n",
    "wp_tag_url=wp_url+\"/tags\"\n",
    "\n",
    "user_id = os.environ['wordpress_username']\n",
    "# user app password can be created in the user/edit user/application password\n",
    "user_app_password = os.environ['wordpress_pass']\n",
    "\n",
    "credentials = user_id + ':' + user_app_password\n",
    "token = base64.b64encode(credentials.encode())\n",
    "header = {'Authorization': 'Basic ' + token.decode('utf-8')}\n",
    "\n",
    "def tags_to_IDs(tag_names=[]):\n",
    "    tags=set()\n",
    "    connection=pymysql.connect(\n",
    "        db     = os.environ['db_name'],\n",
    "        user   = os.environ['db_user'],\n",
    "        passwd = os.environ['db_pass'],\n",
    "        host   = os.environ['db_host'],\n",
    "        port   = 3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    for tag_name in tag_names:\n",
    "        query=\"\"\"SELECT t1.term_id FROM fp_forwardpathway.wp_mmcp_terms t1 JOIN fp_forwardpathway.wp_mmcp_term_taxonomy t2 ON t2.term_id=t1.term_id AND t2.taxonomy=\"post_tag\" WHERE t1.name=%s\"\"\"\n",
    "        rows_count=cursor.execute(query,tag_name)\n",
    "        if rows_count>0:\n",
    "            result=cursor.fetchone()\n",
    "            tags.add(result['term_id'])\n",
    "        else:\n",
    "            tag_data={\"name\":tag_name}\n",
    "            response=requests.post(wp_tag_url,headers=header,json=tag_data)\n",
    "            tags.add(response.json()['id'])\n",
    "            \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return tags\n",
    "    \n",
    "def post_post(article_title, article_body, post_status=\"publish\", featured_media_id=0,tags={}):\n",
    " post_data = {\n",
    "  \"title\": article_title,\n",
    "  \"content\": article_body,\n",
    "  \"comment_status\": \"closed\",\n",
    "  \"categories\": [3627],#美国大学相关新闻category\n",
    "  \"tags\":list(tags),\n",
    "  \"status\": post_status,\n",
    "  \"featured_media\": featured_media_id\n",
    " }\n",
    " try:\n",
    "  response = requests.post(wp_post_url,headers=header, json=post_data)\n",
    " except:\n",
    "  print (\"Error!\")\n",
    "  response = \"\"\n",
    " return response\n",
    "\n",
    "def post_file(file_path):\n",
    "    try:\n",
    "        media = {'file': open(file_path,\"rb\"),'caption': 'LLM_auto_post_test_file_' + file_path}\n",
    "        response = requests.post(wp_media_url, headers = header, files = media)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    return response\n",
    "\n",
    "def generate_image(state):\n",
    "    image_filename=state['image_filename']\n",
    "    image_folder=os.path.join(get_local_folder(),\"images\")\n",
    "    png_image=os.path.join(image_folder,image_filename+\".png\")\n",
    "    jpg_image=os.path.join(image_folder,image_filename+\".jpg\")\n",
    "    image_query=state['image_query']\n",
    "    image_url = DallEAPIWrapper(model='dall-e-3',size='1792x1024',quality='standard').run(image_query)\n",
    "    urllib.request.urlretrieve(image_url,png_image)\n",
    "    image=Image.open(png_image)\n",
    "    image.save(jpg_image,optimized=True,quality=20)\n",
    "    response=post_file(jpg_image)\n",
    "    response=response.json()\n",
    "    return ({\"image_ID\":int(response.get('id')),\"image_url\":response.get('guid').get('rendered')})\n",
    "    \n",
    "def publish_post(state):\n",
    "    title=state['title']\n",
    "    image_ID=state['image_ID']\n",
    "    image_url=state['image_url']\n",
    "    tags=state['tags']\n",
    "    content=markdown.markdown(state['content'].replace(\"[image_placeholder]\",\"\"\"<img src=\"{}\">\"\"\".format(image_url)))\n",
    "    post_post(title, content, post_status=\"publish\", featured_media_id=image_ID,tags=tags)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d97d8c7-e31a-4d3f-9914-1b44d7b250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('summary_node',summary)\n",
    "workflow.add_node('more_topics',more_topics)\n",
    "workflow.add_node('web_search',web_search)\n",
    "workflow.add_node('rewrite',rewrite)\n",
    "workflow.add_node('article_metas',article_metas)\n",
    "workflow.add_node('format_article',format_article)\n",
    "workflow.add_node('generate_image',generate_image)\n",
    "workflow.add_node('publish_post',publish_post)\n",
    "\n",
    "workflow.set_entry_point('summary_node')\n",
    "workflow.add_edge('summary_node','more_topics')\n",
    "workflow.add_edge('more_topics','web_search')\n",
    "workflow.add_edge('web_search','rewrite')\n",
    "workflow.add_edge('rewrite','article_metas')\n",
    "workflow.add_edge('article_metas','format_article')\n",
    "workflow.add_edge('format_article','generate_image')\n",
    "workflow.add_edge('generate_image','publish_post')\n",
    "workflow.add_edge('publish_post',END)\n",
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d527dae-576f-4c75-98e8-17f917e0dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls():\n",
    "    connection=pymysql.connect(\n",
    "        db     = os.environ['db_name'],\n",
    "        user   = os.environ['db_user'],\n",
    "        passwd = os.environ['db_pass'],\n",
    "        host   = os.environ['db_host'],\n",
    "        port   = 3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    query=\"SELECT url FROM fp_chatGPT.news_urls WHERE post IS NULL OR post = 0 ORDER BY RAND() LIMIT 1\"\n",
    "    rows_count=cursor.execute(query)\n",
    "    if rows_count>0:\n",
    "        rows=cursor.fetchall()\n",
    "        urls=[row['url'] for row in rows]\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb88859-ae79-4046-abd8-5e0a37266760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_url_flag(url=''):\n",
    "    if len(url)>0:\n",
    "        connection=pymysql.connect(\n",
    "            db     = os.environ['db_name'],\n",
    "            user   = os.environ['db_user'],\n",
    "            passwd = os.environ['db_pass'],\n",
    "            host   = os.environ['db_host'],\n",
    "            port   = 3306,\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "        query=\"UPDATE fp_chatGPT.news_urls SET post=1 WHERE url=%s\"\n",
    "        cursor.execute(query,url)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64236d7d-b439-46b0-b352-71e34f2e6b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Initial Summary:  https://source.wustl.edu/2024/06/modifying-homes-for-stroke-survivors-saves-lives-extends-independence/\n",
      "------ Topics Summary:  https://www.upi.com/Health_News/2024/06/21/modifying-homes-stroke-survivors-independence/3101718974654/\n",
      "------ Topics Summary:  https://www.unomaha.edu/news/2024/05/advancing-stroke-rehabilitation-through-vr-unos-ground-breaking-research.php\n",
      "------ Topics Summary:  https://www.news-medical.net/news/20240619/Improving-stroke-survivor-health-outcomes-through-home-safety-interventions.aspx\n",
      "------ Topics Summary:  https://www.cbsnews.com/news/3-surprising-ways-long-term-care-insurance-helps-you-age-in-place/\n",
      "1 finished\n"
     ]
    }
   ],
   "source": [
    "urls=get_urls()\n",
    "n_url=0\n",
    "for url in urls:\n",
    "    try:\n",
    "        app.invoke({\"url\":url})\n",
    "        set_url_flag(url)\n",
    "        n_url=n_url+1\n",
    "        print(n_url,\"finished\")\n",
    "    except Exception as e:\n",
    "        print ('error for url: ',url)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a351e50-6a12-4446-99fb-16b55a489c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
